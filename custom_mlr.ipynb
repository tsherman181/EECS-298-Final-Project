{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're out to customize the loss function, so we can't just rely on the closed-form solution of linear regression. The loss function is still differentiable with respect to each model parameter, so we're going to rely on autodifferentiation to implement stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jax.numpy as np\n",
    "import numpy\n",
    "from jax import grad, jit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Census_Micro.csv')\n",
    "df = df.iloc[:10000]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = OneHotEncoder(sparse_output=False).fit_transform(df[['SEX', 'JWTRNS', 'COW', 'SCHL']].to_numpy())\n",
    "X = numpy.concatenate([X, df[['AGEP', 'PWGTP']].to_numpy()], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, numpy.array(df['PERNP']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairLinearRegression:\n",
    "    coefs: np.ndarray\n",
    "    bias: np.ndarray\n",
    "\n",
    "    def __init__(self, X, y, separation_weight=0, A_col=0) -> None:\n",
    "        self.coefs = numpy.random.normal(size=(X.shape[1], ))\n",
    "        self.separation_weight = separation_weight\n",
    "        self.A_col = A_col\n",
    "        self.bias = 0.0\n",
    "        self.jit_loss = jit(self.lr_loss)\n",
    "        self.grad = grad(self.lr_loss, argnums=[0, 2])\n",
    "\n",
    "        self.y_buckets = numpy.unique(numpy.maximum(y // 10000, 0))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.matmul(X, self.coefs) + self.bias\n",
    "\n",
    "    def lr_loss(self, W, X, bias, y):\n",
    "        pred = np.matmul(X, W) + bias\n",
    "        return np.mean((y - pred)**2) + self.separation_weight * self.separation(pred, y, X, self.A_col)\n",
    "\n",
    "    def train_iterate(self, X, y, learning_rate=0.001):\n",
    "        rows = numpy.random.choice(X.shape[0], int(X.shape[0] * 0.1) + 1)\n",
    "        X_batch = X[rows, :]\n",
    "        W_grad, bias_grad = self.grad(self.coefs, X_batch, self.bias, y[rows])\n",
    "        self.coefs -= W_grad * learning_rate\n",
    "        self.bias -= bias_grad * learning_rate\n",
    "    \n",
    "    def train(self, X, y, learning_rate=0.001):\n",
    "        loss = self.lr_loss(self.coefs, X, self.bias, y)\n",
    "        \n",
    "        i = 0\n",
    "        while True:\n",
    "            if i % 100 == 0:\n",
    "                print(i, loss)\n",
    "            self.train_iterate(X, y, learning_rate)\n",
    "            new_loss = self.lr_loss(self.coefs, X, self.bias, y)\n",
    "            if new_loss > loss or abs(new_loss - loss) < 1e-2:\n",
    "                return\n",
    "            loss = new_loss\n",
    "            i += 1\n",
    "\n",
    "    def separation(self, pred, act, X, A_col):\n",
    "        yhat_test_buckets = np.maximum(pred // 10000, 0)\n",
    "        y_test_buckets = np.maximum(act // 10000, 0)\n",
    "\n",
    "        prob_diff_sum = np.array(0)\n",
    "        prob_diff_count = 0\n",
    "        for yhat_bucket in self.y_buckets:\n",
    "            for y_bucket in self.y_buckets:\n",
    "                # P(R | Y, A) = P(R, Y, A) / P(Y, A)\n",
    "\n",
    "                y_a = (X[:, A_col] == 0) & \\\n",
    "                    (y_test_buckets == y_bucket)\n",
    "                r_y_a = y_a & (yhat_test_buckets == yhat_bucket)\n",
    "                prob_a = numpy.sum(r_y_a) / numpy.sum(y_a)\n",
    "\n",
    "                \n",
    "                y_a = (X[:, A_col] == 1) & \\\n",
    "                    (y_test_buckets == y_bucket)\n",
    "                r_y_a = y_a & (yhat_test_buckets == yhat_bucket)\n",
    "                prob_b = numpy.sum(r_y_a) / numpy.sum(y_a)\n",
    "                \n",
    "                prob_diff_sum += 0 if np.isnan(prob_a - prob_b) else abs(prob_a - prob_b)\n",
    "                prob_diff_count += 1\n",
    "        return prob_diff_sum / prob_diff_count if prob_diff_count != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flr.coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flr = FairLinearRegression(X_train, y_train, separation_weight=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flr.lr_loss(flr.coefs, X_train, flr.bias, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flr.train_iterate(X_train, y_train, 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPRegressor(hidden_layer_sizes=(80,))\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numpy.mean((nn.predict(X_test) - y_test)**2))\n",
    "print(numpy.mean((lr.predict(X_test) - y_test)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,61):\n",
    "    flr.train_iterate(X_train, y_train, 2e-5)\n",
    "    if i % 10 == 0:\n",
    "        print(i, flr.lr_loss(flr.coefs, X_train, flr.bias, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the loss without the separation term?\n",
    "spw = flr.separation_weight\n",
    "flr.separation_weight = 0\n",
    "flr.lr_loss(flr.coefs, X_test, flr.bias, y_test)\n",
    "flr.separation_weight = spw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flr.separation(nn.predict(X_test), y_test, X_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flr.separation(lr.predict(X_test), y_test, X_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flr.separation(np.matmul(X_test, flr.coefs) + flr.bias, y_test, X_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(nn.predict(X_train), numpy.matmul(X_train, flr.coefs) + flr.bias)\n",
    "# plt.plot([0, 200000], [0, 200000], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.corrcoef(nn.predict(X_train), numpy.matmul(X_train, flr.coefs) + flr.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.mean(abs(nn.predict(X_train) - y_train) < 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness metrics\n",
    "We now turn to the computation of fairness metrics for a given set of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = numpy.matmul(X_test, flr.coefs) + flr.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is independence with respect to sex\n",
    "# E[Yhat | Sex = Male], E[Yhat | Sex = Female]\n",
    "(numpy.mean(yhat_test[X_test[:, 0] == 0]).item(), numpy.mean(yhat_test[X_test[:, 0] == 1]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is separation with respect to sex\n",
    "# (Key enhancement to this metric is to make it work on continuous R and Y.\n",
    "#  To apply its categorical definition, we've had to make income brackets. The creation\n",
    "#  of these brackets is a source of bias by itself.)\n",
    "# P[Yhat | Y, Sex = Male] = P[Yhat | Y, Sex = Female]\n",
    "\n",
    "yhat_test_buckets = numpy.maximum(yhat_test // 10000, 0)\n",
    "y_test_buckets = numpy.maximum(y_test // 10000, 0)\n",
    "\n",
    "prob_diffs = []\n",
    "for yhat_bucket in numpy.unique(yhat_test_buckets):\n",
    "    for y_bucket in numpy.unique(y_test_buckets):\n",
    "        # female\n",
    "        prob_a = numpy.mean(yhat_test_buckets[(X_test[:, 0] == 0) & (y_test_buckets == y_bucket)] == yhat_bucket)\n",
    "        # male\n",
    "        prob_b = numpy.mean(yhat_test_buckets[(X_test[:, 0] == 1) & (y_test_buckets == y_bucket)] == yhat_bucket)\n",
    "        if not (numpy.isnan(prob_a) or numpy.isnan(prob_b)):\n",
    "            prob_diffs.append(prob_a - prob_b)\n",
    "print(numpy.mean(numpy.abs(prob_diffs)))\n",
    "plt.hist(prob_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is sufficiency with respect to sex\n",
    "# (Key enhancement to this metric is to make it work on continuous R and Y.\n",
    "#  To apply its categorical definition, we've had to make income brackets. The creation\n",
    "#  of these brackets is a source of bias by itself.)\n",
    "# P[Y | Yhat, Sex = Male] = P[Y | Yhat, Sex = Female]\n",
    "\n",
    "\n",
    "suff_prob_diffs = []\n",
    "for yhat_bucket in numpy.unique(yhat_test_buckets):\n",
    "    for y_bucket in numpy.unique(y_test_buckets):\n",
    "        # female\n",
    "        prob_a = numpy.mean(y_test_buckets[(X_test[:, 0] == 0) & (yhat_test_buckets == yhat_bucket)] == y_bucket)\n",
    "        # male\n",
    "        prob_b = numpy.mean(y_test_buckets[(X_test[:, 0] == 1) & (yhat_test_buckets == yhat_bucket)] == y_bucket)\n",
    "        if not (numpy.isnan(prob_a) or numpy.isnan(prob_b)):\n",
    "            suff_prob_diffs.append(prob_a - prob_b)\n",
    "print(numpy.mean(numpy.abs(suff_prob_diffs)))\n",
    "plt.hist(suff_prob_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
